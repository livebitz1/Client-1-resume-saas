import express from 'express';\nimport multer from 'multer';\nimport path from 'path';\nimport { fileURLToPath } from 'url';\nimport dotenv from 'dotenv';\n// Native fetch and FormData are available in Node.js 18+\n// If using older Node, you might need 'node-fetch' and 'form-data' packages.\n\ndotenv.config(); // Load .env file for local development\n\nconst app = express();\nconst port = process.env.PORT || 3001;\n\n// --- Configuration ---\nconst EDEN_AI_API_KEY = process.env.EDEN_AI_API_KEY;\nconst OPENAI_API_KEY = process.env.OPENAI_API_KEY;\n\nconst EDEN_AI_RESUME_PARSER_URL = \"https://api.edenai.run/v2/ocr/resume_parser\";\nconst EDEN_AI_PROVIDER = \"senseloaf\"; // Or affinda, hireability, etc.\nconst OPENAI_API_URL = \"https://api.openai.com/v1/chat/completions\";\nconst OPENAI_MODEL = \"gpt-4o\";\n\n// --- Middleware ---\napp.use(express.json()); // For parsing application/json\n\n// Multer setup for file uploads (in-memory storage)\nconst storage = multer.memoryStorage();\nconst upload = multer({\n  storage: storage,\n  limits: { fileSize: 5 * 1024 * 1024 }, // 5MB limit\n  fileFilter: (req, file, cb) => {\n    const allowedTypes = [\n      \"application/pdf\",\n      \"application/msword\",\n      \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\",\n    ];\n    if (allowedTypes.includes(file.mimetype)) {\n      cb(null, true);\n    }\n    else {\n      cb(new Error(\"Invalid file type. Only PDF and Word documents are allowed.\"), false);\n    }\n  },\n});\n\n// --- API Endpoint for Resume Analysis ---\napp.post('/api/analyze-resume', upload.single('resumeFile'), async (req, res) => {\n  if (!req.file) {\n    return res.status(400).json({ success: false, error: 'No resume file uploaded.' });\n  }\n\n  if (!EDEN_AI_API_KEY || !OPENAI_API_KEY) {\n    console.error(\"SERVER_ERROR: API keys not configured on the server.\");\n    return res.status(500).json({ success: false, error: 'Server configuration error: API keys missing.' });\n  }\n\n  const resumeFileBuffer = req.file.buffer;\n  const resumeFileName = req.file.originalname;\n  const resumeFileMimeType = req.file.mimetype;\n\n  let edenAIStructuredData;\n  let rawEdenAIResponse;\n\n  try {\n    console.log(`BACKEND: Calling Eden AI resume_parser (${EDEN_AI_PROVIDER})...`);\n    const edenFormData = new FormData();\n    edenFormData.append('providers', EDEN_AI_PROVIDER);\n    edenFormData.append('file', new Blob([resumeFileBuffer], { type: resumeFileMimeType }), resumeFileName);\n\n    const edenResponse = await fetch(EDEN_AI_RESUME_PARSER_URL, {\n      method: 'POST',\n      headers: { Authorization: `Bearer ${EDEN_AI_API_KEY}` },\n      body: edenFormData,\n    });\n\n    rawEdenAIResponse = await edenResponse.json();\n\n    if (!edenResponse.ok) {\n      const errorMsg = rawEdenAIResponse?.[EDEN_AI_PROVIDER]?.error?.message || rawEdenAIResponse?.[\"eden-ai\"]?.error?.message || `Eden AI API request failed with status ${edenResponse.status}`;\n      console.error(`BACKEND: Eden AI API Error: ${errorMsg}`, rawEdenAIResponse);\n      return res.status(edenResponse.status || 500).json({ success: false, error: errorMsg, rawEdenAIResponse });\n    }\n\n    const providerResult = rawEdenAIResponse?.[EDEN_AI_PROVIDER] || rawEdenAIResponse?.[\"eden-ai\"];\n    if (providerResult?.status !== 'success' || !providerResult?.extracted_data) {\n      const errorMsg = providerResult?.error?.message || 'Eden AI provider failed to parse resume or no data extracted.';\n      console.error(`BACKEND: Eden AI Provider Error: ${errorMsg}`, providerResult);\n      return res.status(400).json({ success: false, error: errorMsg, rawEdenAIResponse });\n    }\n    edenAIStructuredData = providerResult.extracted_data;\n    console.log('BACKEND: Eden AI parsing successful.');\n\n  }\n  catch (error) {\n    console.error('BACKEND: Exception during Eden AI call:', error);\n    return res.status(500).json({ success: false, error: `Eden AI processing failed: ${error.message}` });\n  }\n\n  // Step 2: Enhance with OpenAI\n  let rawOpenAIResponse;\n  try {\n    console.log('BACKEND: Calling OpenAI to enhance resume data...');\n    const openAIPrompt = `\n      You are an expert resume writer and career coach.\n      Based on the following structured resume data extracted by an AI parser, please generate a professional and compelling output.\n      The output should be a JSON object containing:\n      1.  \"professionalSummary\": A concise, impactful professional summary (2-4 sentences).\n      2.  \"enhancedWorkExperience\": An array of work experience objects. For each experience, rewrite the description into 2-3 impactful bullet points using action verbs. Each object should have \"title\", \"company\", \"dates\", and \"bulletPoints\" (an array of strings).\n      3.  \"keySkills\": A list of 5-7 key skills highlighted in the resume.\n      4.  \"educationHighlights\": A brief highlight of the education if significant.\n\n      Here is the structured data from the initial parsing:\n      \`\`\`json\n      ${JSON.stringify(edenAIStructuredData, null, 2)}\n      \`\`\`\n\n      Ensure your response is only the JSON object.\n    `;\n\n    const openAIAPIResponse = await fetch(OPENAI_API_URL, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        Authorization: `Bearer ${OPENAI_API_KEY}`,\n      },\n      body: JSON.stringify({\n        model: OPENAI_MODEL,\n        messages: [{\n          role: 'user',\n          content: openAIPrompt\n        }],\n        response_format: { type: 'json_object' },\n        temperature: 0.5,\n      }),\n    });\n\n    rawOpenAIResponse = await openAIAPIResponse.json();\n\n    if (!openAIAPIResponse.ok) {\n      const errorMsg = rawOpenAIResponse?.error?.message || `OpenAI API request failed with status ${openAIAPIResponse.status}`;\n      console.error(`BACKEND: OpenAI API Error: ${errorMsg}`, rawOpenAIResponse);\n      return res.status(openAIAPIResponse.status || 500).json({\n        success: false,\n        error: errorMsg,\n        rawOpenAIResponse,\n        rawEdenAIResponse\n      });\n    }\n\n    const openAIContent = rawOpenAIResponse.choices?.[0]?.message?.content;\n    if (!openAIContent) {\n      console.error('BACKEND: OpenAI response content is missing.', rawOpenAIResponse);\n      return res.status(500).json({\n        success: false,\n        error: 'OpenAI did not return valid content.',\n        rawOpenAIResponse,\n        rawEdenAIResponse\n      });\n    }\n\n    try {\n      const professionalTemplateData = JSON.parse(openAIContent);\n      console.log('BACKEND: OpenAI enhancement successful.');\n      return res.json({\n        success: true,\n        message: 'Resume processed and enhanced successfully!',\n        data: professionalTemplateData,\n        rawEdenAIResponse,\n        rawOpenAIResponse,\n      });\n    }\n    catch (jsonError) {\n      console.error('BACKEND: Failed to parse OpenAI JSON content:', jsonError, 'Raw content:', openAIContent);\n      return res.status(500).json({\n        success: false,\n        error: \"Error processing OpenAI's response format.\",\n        rawOpenAIResponse: { raw_content: openAIContent, ...rawOpenAIResponse },\n        rawEdenAIResponse\n      });\n    }\n  }\n  catch (error) {\n    console.error('BACKEND: Exception during OpenAI call:', error);\n    return res.status(500).json({\n      success: false,\n      error: `OpenAI processing failed: ${error.message}`,\n      rawEdenAIResponse\n    });\n  }\n});\n\n// --- Serve Static Frontend Assets (for Production) ---\n// Get the directory name of the current module\nconst __filename = fileURLToPath(import.meta.url);\nconst __dirname = path.dirname(__filename);\n\nif (process.env.NODE_ENV === 'production') {\n  app.use(express.static(path.join(__dirname, 'dist')));\n\n  // For any other route, serve the index.html from Vite's build\n  app.get('*', (req, res) => {\n    res.sendFile(path.join(__dirname, 'dist', 'index.html'));\n  });\n}\n\n// --- Start Server ---\napp.listen(port, () => {\n  console.log(`Server listening on port ${port}`);\n  if (process.env.NODE_ENV !== 'production') {\n    console.log('In development, Vite dev server should be run separately for frontend HMR.');\n    console.log('Ensure Vite is configured to proxy /api requests to this server (e.g., http://localhost:3001).');\n  }\n  else {\n    console.log('Serving production build from ./dist');\n  }\n}); 